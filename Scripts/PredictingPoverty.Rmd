---
title: "Problem Set 2 - BDML"
author: "Cristian Muñoz - Vivian Cabanzo - Zenneth Olivero - Laura Diaz"
date: "2025-09-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Predicting Poverty

# Predicción de Pobreza en Colombia

## 1. Introducción

## 2. Datos

### 2.1. Limpieza de datos

### - Paquetes y librerias

A continuación se cargan los paquetes y librerias necesarias para el análisis de información.

```{r}
# Instalar y cargar pacman (gestor de paquetes)
if (!require("pacman")) install.packages("pacman")
library(pacman)

# Cargar paquetes necesarios
pacman::p_load(
  knitr,         # Knit en RMarkdown
  tidyverse,     # Incluye dplyr, tidyr, ggplot2, readr, purrr
  readxl,        # Lectura de Excel
  janitor,       # Limpieza rápida
  skimr,         # Resúmenes descriptivos
  styler,        # Estilo de código
  corrplot,      # Matrices de correlación
  boot,          # Bootstrap
  modelsummary,  # Resúmenes en tablas
  scales,        # Para formatear ejes
  gt,            # Tablas elegantes
  broom,         # Modelos -> data.frames
  survey,        # Encuestas complejas
  rio,           # Importar/exportar
  stargazer,     # Estadísticas descriptivas y modelos
  gtsummary,     # Tablas médicas/sociales
  gridExtra,     # Organizar gráficos
  labelled,      # Manejo de etiquetas
  tibble,        # Tablas en consola
  kableExtra,    # Mejorar tablas
  stringi,       # Convertir Carácteres
  webshot2,      # Guardar HTML y PDF
  caret,         # Herramientas preprocesamiento, selección de modelos y evaluación de algoritmos de ML
  glmnet,        # Implementación eficiente de modelos de regresión regularizados (EN, Lasso y Ridge)
  MLeval,        # Funciones para evaluar modelos de clasificación y regresión con métricas y gráficos
  MLmetrics,     # Colección de métricas de evaluación para modelos de machine learning
  rpart,         # Implementar arboles de decision
  rpart.plot,    # Graficos de arboles
  Metrics,      # Evaluar modelos predictivos
  ROCR)

# Verificar paquetes cargados
pacman::p_loaded()

```

### - Cargar bases de datos

Se proceden a cargar las bases de datos definidas para el análisis.

**Nota:** En primera instancia, se debe garantizar la reproducibilidad del script para cualquier usuario, por lo que se precisa la necesidad de que, tanto el arhivo R Markdown como las bases de datos se almacenen en la misma carpeta o ruta.

```{r}
# Lista de datasets que deben estar en la misma carpeta del .Rmd
Datasets <- c(
  "sample_submission.csv",
  "train_hogares.csv",
  "train_personas.csv",
  "test_hogares.csv",
  "test_personas.csv"
)

# Verificación
for (Dataset in Datasets) {
  if (file.exists(Dataset)) {
    cat("El dataset", Dataset, "se encuentra en la carpeta para su respectivo cargue a R.\n")
  } else {
    cat("El dataset", Dataset, "NO se encuentra en la carpeta para su respectivo cargue a R.\n")
  }
}

```

Posteriormente, se proceden a cargar los datasets

```{r}
# Cargar datasets en R
sample_submission <- read.csv("sample_submission.csv", stringsAsFactors = FALSE)
train_hogares     <- read.csv("train_hogares.csv", stringsAsFactors = FALSE)
train_personas    <- read.csv("train_personas.csv", stringsAsFactors = FALSE)
test_hogares      <- read.csv("test_hogares.csv", stringsAsFactors = FALSE)
test_personas     <- read.csv("test_personas.csv", stringsAsFactors = FALSE)

# Confirmar cargue mostrando dimensiones de cada dataset
cat("sample_submission:", nrow(sample_submission), "filas y", ncol(sample_submission), "columnas.\n")
cat("train_hogares:", nrow(train_hogares), "filas y", ncol(train_hogares), "columnas.\n")
cat("train_personas:",nrow(train_personas), "filas y", ncol(train_personas), "columnas.\n")
cat("test_hogares:", nrow(test_hogares), "filas y", ncol(test_hogares), "columnas.\n")
cat("test_personas:", nrow(test_personas), "filas y", ncol(test_personas), "columnas.\n")

```

### - Exploración de bases de datos

Se analizan la bases de datos de entrenamiento y de prueba correspondiente a hogares y a personas, es necesario tener en cuenta que el objetivo es predecir la pobreza a nivel de hogares, por lo que es posible crear variables relevantes para la predicción de pobreza desde el nivel de personas para robustecer los resultados.

Analisis de las bases de datos de entrenamiento y de prueba a nivel de hogares:

```{r}
# Comparar variables entre train y test Hogares
vars_comunes_hog <- intersect(names(train_hogares), names(test_hogares))
vars_train_hog <- setdiff(names(train_hogares), names(test_hogares))
vars_test_hog <- setdiff(names(test_hogares), names(train_hogares))

# Variables exclusivas en test
solo_test_hog <- if (length(vars_test_hog) == 0) "Ninguna variable" else paste(vars_test_hog, collapse = ", ")

# Construir tabla resumen
comp_bd_hogares <- tibble(
  Categoria = c("En ambos datasets", "Solo en train_hogares", "Solo en test_hogares"),
  Cantidad  = c(length(vars_comunes_hog), length(vars_train_hog), ifelse(length(vars_test_hog) == 0, 0, length(vars_test_hog))),
  Variables = c(
    paste(vars_comunes_hog, collapse = ", "),
    paste(vars_train_hog, collapse = ", "),
    solo_test_hog
  )
)

# Crear tabla gt
comp_bd_hogares <- comp_bd_hogares %>%
  gt() %>%
  tab_header(
    title = "Resumen de Variables entre la muestra de entrenamiento y de prueba en Hogares"
  ) %>%
  cols_label(
    Categoria = "Categoría",
    Cantidad = "N° de Variables",
    Variables = "Variables"
  )

# Crear carpeta "Tablas y Graficos"
if (!dir.exists("Tablas y Graficos")) dir.create("Tablas y Graficos")

# Exportar en HTML, PDF y PNG dentro de "Tablas y Graficos"
gtsave(comp_bd_hogares, "Tablas y Graficos/1.Comparacion_bases_hogares.html")

webshot2::webshot(
  "Tablas y Graficos/1.Comparacion_bases_hogares.html",
  "Tablas y Graficos/1.Comparacion_bases_hogares.pdf"
)

gtsave(comp_bd_hogares, "Tablas y Graficos/1.Comparacion_bases_hogares.png")


# Mostrar en pantalla
comp_bd_hogares

```

La Tabla que precede presenta un resumen comparativo de las variables disponibles en la muestra de entrenamiento y de prueba a nivel de hogares, se observa que ambas bases comparten un total de 16 variables, entre ellas el identificador del hogar (id), atributo fundamental para la creacion de nuevas variables, así como variables socioeconómicas y demográficas.

Adicionalmente, se identifican 7 variables exclusivas de la base de entrenamiento (Ingtotug, Ingtotugarr, Ingpcug, Pobre, Indigente, Npobres, Nindigentes), las cuales no están presentes en la base de prueba. Por su parte, el conjunto de prueba no presenta variables exclusivas, lo cual se señala explícitamente como "Ninguna variable".


A cotinuación se presenta la comparación de variables entre las muestras de entrenamiento y de prueba a nivel de hogares, se examinan de manera sistemática aspectos como el tipo de dato para identificar la consistencia en el tipo de variables en ambas bases de datos.


```{r}
# Función: obtener tipo de variable para un dataset
tipo_var_hogares <- function(df) {
  map_dfr(names(df), function(var) {
    tibble(
      Variable = var,
      Tipo = class(df[[var]])[1]
    )
  })
}

# Calcular tipos para train y test
var_train_hog <- tipo_var_hogares(train_hogares)
var_test_hog <- tipo_var_hogares(test_hogares)

# Unir en una sola tabla comparativa
comb_tipo_var_hog <- full_join(
  var_train_hog %>% rename_with(~paste0(., "_train"), -Variable),
  var_test_hog  %>% rename_with(~paste0(., "_test"), -Variable),
  by = "Variable"
)

# Reemplazar NA
comb_tipo_var_hog <- comb_tipo_var_hog %>%
  mutate(
    Tipo_train = ifelse(is.na(Tipo_train), "No existe variable en el dataset", Tipo_train),
    Tipo_test  = ifelse(is.na(Tipo_test),  "No existe variable en el dataset", Tipo_test)
  )

# Crear tabla con gt
comb_tipo_var_hog <- comb_tipo_var_hog %>%
  select(Variable, Tipo_train, Tipo_test) %>%
  gt() %>%
  tab_header(
    title = "Tipo de Variables: Muestra de entrenamiento y de prueba en Hogares"
  ) %>%
  tab_spanner(
    label = "Muestra de Entrenamiento",
    columns = c(Tipo_train)
  ) %>%
  tab_spanner(
    label = "Muestra de Prueba",
    columns = c(Tipo_test)
  ) %>%
  cols_label(
    Variable = "Variable",
    Tipo_train = "Tipo de variable",
    Tipo_test = "Tipo de variable"
  )

# Exportar dentro de la subcarpeta "Tablas y Graficos"
gtsave(comb_tipo_var_hog, "Tablas y Graficos/2.Comparacion_tipo_var_hogares.html")

webshot2::webshot(
  "Tablas y Graficos/2.Comparacion_tipo_var_hogares.html",
  "Tablas y Graficos/2.Comparacion_tipo_var_hogares.pdf"
)

gtsave(comb_tipo_var_hog, "Tablas y Graficos/2.Comparacion_tipo_var_hogares.png")

# Mostrar en pantalla
comb_tipo_var_hog

```

En conjunto, esta tabla complementa el análisis previo y constituye una herramienta fundamental para orientar las decisiones de limpieza, imputación y selección de variables en la construcción del modelo de predicción de pobreza.

Por otra parte, es fundamental que las bases de datos de entrenamiento y de prueba utilicen el mismo conjunto de variables explicativas, esto se debe a que el modelo predictivo aprende una función definida en un espacio de características específico; si en la etapa de predicción se presentan variables distintas a las utilizadas en el entrenamiento, los modelos a plantear carecerían de la información necesaria para generar resultados válidos. 

De igual forma, la inclusión de variables adicionales en el entrenamiento que no están presentes en la prueba impide evaluar correctamente la capacidad de predicción de modelos. Es importante resaltar que, la variable objetivo "Pobre" está disponible únicamente en la base de entrenamiento y no en la base de prueba, ya que el propósito principal del analisis es generar predicciones de pobreza a partir de datos conocidos.

Teniendo en cuenta lo anterior, en primera instancia, se define a un hogar como pobre cuando el ingreso del hogar es inferior a la "Linea de Pobreza", como se define a continuación:

$$
\
Pobre = I \cdot (Ingreso < \text{Línea de Pobreza})
\
$$
Se asigna el valor de la variable "Pobre" de acuerdo con el resultado de la función que precede, 

$$
\
Donde \ I:
\\
I(\text{Función indicadora}) =
\begin{cases} 
0, & \text{Ingreso superior a la linea de pobreza = No Pobre} \\
1, & \text{Ingreso inferior a la linea de pobreza = Pobre}
\end{cases}
\
$$


De acuerdo con la definición anterior, se seleccionan en la base de datos de entrenamiento aquellas variables que se encuentran en la base de prueba y se mantiene la variable objetivo "Pobre", con la cual se entrenarán los diferentes modelos para realizar predicciones en la base de prueba.

```{r}
# Variables en común entre train y test hogares
vars_comunes_hog

# Mantener las variables comunes y "Pobre"
vars_comunes_hog <- c(vars_comunes_hog, "Pobre")

# Filtro de train_hogares
train_hogares2 <- train_hogares %>%
  select(all_of(vars_comunes_hog))

# Verificar
cat("Número de variables en train original:", ncol(train_hogares), "\n")
cat("Número de variables en train depurado:", ncol(train_hogares2), "\n")

```
Al realizar la depuración inicial se exploran las variables restantes, con el objetivo de comprenderlas a fondo y definir su relevancia dentro de la prediccion de pobreza de los hogares.


```{r}
# Renombrar variables en train_hogares2
train_hogares2 <- train_hogares2 %>%
  rename(
    Total_habitaciones = P5000,
    Dormitorios = P5010,
    Tipo_vivienda = P5090,
    Cuota_amortizacion = P5100,
    Valor_estimado_arriendo = P5130,
    Valor_arriendo = P5140,
  )

# Renombrar variables en test_hogares igual que en train_hogares
test_hogares2 <- test_hogares %>%
  rename(
    Total_habitaciones = P5000,
    Dormitorios = P5010,
    Tipo_vivienda = P5090,
    Cuota_amortizacion = P5100,
    Valor_estimado_arriendo = P5130,
    Valor_arriendo = P5140,
  )

# Crear diccionario de variables
diccionario_vars <- tibble::tibble(
  Variable = names(train_hogares2),
  Descripcion = "Descripción pendiente"
)

# Si deseas agregar descripciones personalizadas a algunas variables conocidas:
diccionario_vars <- diccionario_vars %>%
  mutate(
    Descripcion = case_when(
      Variable == "id" ~ "Llave única del hogar",
      Variable == "Clase" ~ "1. Cabecera; 2. Resto (centros poblados y rural dispersa)",
      Variable == "Dominio" ~ "Dominio geográfico: áreas metropolitanas, cabeceras y resto",
      Variable == "Total_habitaciones" ~ "Total de habitaciones del hogar",
      Variable == "Dormitorios" ~ "Número de dormitorios",
      Variable == "Tipo_vivienda" ~ "Tipo de vivienda: a.Propia, totalmente pagada 
    b. Propia, la están pagando
    c. En arriendo o subarriendo
    d. En usufructo e. Posesión sin titulo (ocupante)
    f. Otra",
      Variable == "Cuota_amortizacion" ~ "Valor de cuota de amortización de vivienda",
      Variable == "Valor_estimado_arriendo" ~ "Valor estimado del arriendo de la vivienda",
      Variable == "Valor_arriendo" ~ "Valor real de arriendo mensual",
      Variable == "Nper" ~ "Número de personas en el hogar",
      Variable == "Npersug" ~ "Número de personas en la unidad de gasto",
      Variable == "Li" ~ "Línea de Indigencia",
      Variable == "Lp" ~ "Línea de Pobreza",
      Variable == "Fex_c" ~ "Factor de Expansión",
      Variable == "Depto" ~ "Departamento de residencia",
      Variable == "Fex_dpto" ~ "Factor de Expansión departamental",
      Variable == "Pobre" ~ "1 = Pobre ; 0 = No pobre (solo en entrenamiento)",
      TRUE ~ Descripcion
    )
  )

# Crear tabla con gt
diccionario_vars <- diccionario_vars %>%
  gt() %>%
  tab_header(
    title = "Diccionario de Variables: train_hogares2"
  ) %>%
  cols_label(
    Variable = "Variable",
    Descripcion = "Descripción"
  )

# Exportar en los tres formatos dentro de la carpeta

# HTML
gtsave(diccionario_vars, "Tablas y Graficos/3.Diccionario_train_hogares2.html")

# PDF
webshot2::webshot(
  "Tablas y Graficos/3.Diccionario_train_hogares2.html",
  "Tablas y Graficos/3.Diccionario_train_hogares2.pdf"
)

# PNG
gtsave(diccionario_vars, "Tablas y Graficos/3.Diccionario_train_hogares2.png")

# Mostrar en pantalla
diccionario_vars

```


Es necesario resaltar que, si bien las variables que contiene ingresos en la base de entrenamiento fueron eliminadas, no presenta ninguna implicacion ya que, dentro de la base existe la variable "Pobre", la cual por definición representa que los ingresos de determinados hogares son inferiores a la linea de pobreza.

A contiuación, se presentan las variables contenidas en el dataset de entrenamiento de Hogares y se exploran los valores faltantes.

```{r}
# Calcular % de faltantes en TRAIN hogares
faltantes_train_hog <- train_hogares2 %>%
  summarise(across(everything(), ~mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Porcentaje_NA") %>%
  mutate(Base = "Entrenamiento")

# Calcular % de faltantes en TEST hogares
faltantes_test_hog <- test_hogares2 %>%
  summarise(across(everything(), ~mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Porcentaje_NA") %>%
  mutate(Base = "Prueba")

# Unir ambas bases
faltantes_comp_hog <- bind_rows(faltantes_train_hog, faltantes_test_hog)

# Reordenar factores id, Clase, Dominio y Depto 
orden_vars <- c(setdiff(unique(faltantes_comp_hog$Variable), 
                        c("Depto", "Dominio","Clase", "id")),
                      "Depto", "Dominio","Clase", "id")

faltantes_comp_hog <- faltantes_comp_hog %>%
  mutate(Variable = factor(Variable, levels = orden_vars))

# Gráfico comparativo
grafico_faltantes <- ggplot(faltantes_comp_hog, aes(x = Variable, 
                                                y = Porcentaje_NA, fill = Base)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = paste0(round(Porcentaje_NA, 2), "%")), 
            position = position_dodge(width = 0.9), 
            vjust = -0.3, size = 3) +
  coord_flip() +
  labs(title = "Comparación de % de valores faltantes por variable\nTrain vs Test (hogares)",
       x = "Variable", y = "% de valores faltantes") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_fill_manual(values = c("Entrenamiento" = "lightyellow4",
                               "Prueba"        = "#FFFF00")) 

# Exportar gráfico a PDF
ggsave(
  filename = "Tablas y Graficos/4.Faltantes_Train_Hogares.pdf",
  plot = grafico_faltantes,
  width = 10, height = 6
)

# Exportar gráfico a PNG
ggsave(
  filename = "Tablas y Graficos/4.Faltantes_Train_Hogares.png",
  plot = grafico_faltantes,
  width = 10, height = 6,
  dpi = 300
)

# Mostrar en pantalla
print(grafico_faltantes)

```


La gráfica que precede, ofrece una visión más precisa de la calidad de los datos, resaltando aquellas variables con un porcentaje considerable de valores faltantes que podrían comprometer el desempeño de los modelos predictivos. Se evidencia un alto porcentaje de datos faltantes en las mismas variables para las dos bases, a saber, el valor estimado en caso de pagar arriendo en una vivienda, la cuota de amortización por crédito hipotecario y el valor actual del arriendo, por lo que dichas variables podrian omitirse en ambas bases.

Adicionalmente, las demás variables no presentan datos faltantes, sin embargo, "id", "Clase", "Dominio" y "Depto" son atributos de identificacion por lo que no se usarán como posibles predictoras aunque se mantengan en la base.

Por su parte, los factores de expansión no representan caracteristicas intrinsecas que contribuyan a la predicción del estado de pobreza de un hogar en Colombia, estas corresponden a atributos para el analisis poblacional por lo que no se utilizarán para predecir.

En cuanto a la linea de pobreza y a la linea de indigencia, estas variables no son necesarias puesto que ya existe la variable que clasifica a los hogares pobres de aquellos que no lo son.

Por lo anterior, dentro de lo explorado se mantendrán las variables "Tipo de vivienda" y "Numero de personas en el hogar", en este orden de ideas se debe proceder a explorar las bases de entrenamiento y de prueba en el nivel de Personas para identificar posibles variables que contribuyan a la prediccion adecuada del estado de pobreza.


```{r}
# Comparar variables entre train y test Personas
vars_comunes_pers <- intersect(names(train_personas), names(test_personas))
vars_train_pers <- setdiff(names(train_personas), names(test_personas))
vars_test_pers <- setdiff(names(test_personas), names(train_personas))

# Variables exclusivas en test
solo_test_pers <- if (length(vars_test_pers) == 0) "Ninguna variable" else paste(vars_test_pers, collapse = ", ")

# Construir tabla resumen
comp_bd_personas <- tibble(
  Categoria = c("En ambos datasets", "Solo en train_personas", "Solo en test_personas"),
  Cantidad  = c(length(vars_comunes_pers), length(vars_train_pers), ifelse(length(vars_test_pers) == 0, 0, length(vars_test_pers))),
  Variables = c(
    paste(vars_comunes_pers, collapse = ", "),
    paste(vars_train_pers, collapse = ", "),
    solo_test_pers
  )
)

# Crear tabla gt
comp_bd_personas <- comp_bd_personas %>%
  gt() %>%
  tab_header(
    title = "Resumen de Variables entre la muestra de entrenamiento y de prueba en Hogares"
  ) %>%
  cols_label(
    Categoria = "Categoría",
    Cantidad = "N° de Variables",
    Variables = "Variables"
  )

# Crear carpeta "Tablas y Graficos"
if (!dir.exists("Tablas y Graficos")) dir.create("Tablas y Graficos")

# Exportar en HTML, PDF y PNG dentro de "Tablas y Graficos"
gtsave(comp_bd_personas, "Tablas y Graficos/5.Comparacion_bases_personas.html")

webshot2::webshot(
  "Tablas y Graficos/5.Comparacion_bases_personas.html",
  "Tablas y Graficos/5.Comparacion_bases_personas.pdf"
)

gtsave(comp_bd_personas, "Tablas y Graficos/5.Comparacion_bases_personas.png")

# Mostrar en pantalla
comp_bd_personas

```
Del analisis de las variables en común en las bases de Personas, se identifican 63 que se encuentran en la base de entrenamiento y de prueba, se procederá a realizar un analisis de valores faltantes para seleccionar de forma adecuada variables que permitan predecir el estado de pobreza.



```{r}
# Calcular % de faltantes en TRAIN_PERSONAS y TEST_PERSONAS
faltantes_train_pers <- train_personas %>%
  select(all_of(vars_comunes_pers)) %>%
  summarise(across(everything(), ~mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Porcentaje_NA") %>%
  mutate(Base = "Train Personas")

faltantes_test_pers <- test_personas %>%
  select(all_of(vars_comunes_pers)) %>%
  summarise(across(everything(), ~mean(is.na(.)) * 100)) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Porcentaje_NA") %>%
  mutate(Base = "Test Personas")

# Unir y clasificar en rangos de % de faltantes
faltantes_comp_pers <- bind_rows(faltantes_train_pers, faltantes_test_pers) %>%
  mutate(
    Categoria = case_when(
      Porcentaje_NA == 0 ~ "0%",
      Porcentaje_NA > 0 & Porcentaje_NA <= 30 ~ "1% - 30%",
      Porcentaje_NA > 30 & Porcentaje_NA <= 50 ~ "31% - 50%",
      Porcentaje_NA > 50 & Porcentaje_NA < 100 ~ "51% - 99%",
      Porcentaje_NA == 100 ~ "100%"
    )
  ) %>%
  group_by(Base, Categoria) %>%
  summarise(N_variables = n(), .groups = "drop")

# Crear gráfico resumido
porc_faltantes_pers <- ggplot(faltantes_comp_pers, aes(x = Categoria, y = N_variables, fill = Base)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(
    aes(label = N_variables),
    position = position_dodge(width = 0.9),
    vjust = -0.3, size = 4
  ) +
  labs(
    title = "Distribución de variables comunes según % de faltantes\nMuestra de entrenamiento y prueba de Personas",
    x = "Categoría de % de faltantes", y = "Número de variables"
  ) +
  theme_minimal(base_size = 12) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
  scale_fill_manual(
    values = c("Train Personas" = "lightyellow4",  # verde oliva oscuro
               "Test Personas"  = "#FFD700")  # amarillo dorado
  )


# Exportar gráfico en PDF y PNG dentro de "Tablas y Graficos"
# PDF
ggsave(
  filename = "Tablas y Graficos/6.Resumen_Faltantes_Train_vs_Test_Personas.pdf",
  plot = porc_faltantes_pers,
  width = 8, height = 6
)

# PNG
ggsave(
  filename = "Tablas y Graficos/6.Resumen_Faltantes_Train_vs_Test_Personas.png",
  plot = porc_faltantes_pers,
  width = 8, height = 6,
  dpi = 300
)

# Mostrar en consola
print(porc_faltantes_pers)

```

De acuerdo con la grafica, existen 45 variables con mas del 50% de valores faltantes en las dos bases a nivel de personas, por lo que no es procedente tenerlas en cuenta para el entrenamiento. Por su parte, 18 variables se revisarán a continuación:



```{r}
# Crear tabla detallada de % de faltantes
# Unir porcentajes de faltantes de train y test lado a lado
faltantes_detalle_pers <- left_join(
  faltantes_train_pers %>% rename(Pct_Faltantes_Train = Porcentaje_NA),
  faltantes_test_pers  %>% rename(Pct_Faltantes_Test = Porcentaje_NA),
  by = "Variable"
)

# Clasificar categorías
faltantes_detalle_pers <- faltantes_detalle_pers %>%
  mutate(
    Categoria = case_when(
      Pct_Faltantes_Train == 0 & Pct_Faltantes_Test == 0 ~ "0% faltantes",
      (Pct_Faltantes_Train >= 1 & Pct_Faltantes_Train <= 30) |
        (Pct_Faltantes_Test >= 1 & Pct_Faltantes_Test <= 30) ~ "1% - 30%",
      TRUE ~ "Más del 30%"
    )
  )

# Filtrar solo variables con 0%-30% faltantes
faltantes_interes_pers <- faltantes_detalle_pers %>%
  filter(Categoria %in% c("0% faltantes", "1% - 30%")) %>%
  select(Variable, Pct_Faltantes_Train, Pct_Faltantes_Test)

# Crear tabla con gt
tabla_faltantes_pers <- faltantes_interes_pers %>%
  gt() %>%
  tab_header(
    title = "Variables con valores faltantes (0%-30%)\nTrain Personas vs Test Personas"
  ) %>%
  cols_label(
    Variable = "Variable",
    Pct_Faltantes_Train = "% Faltantes Train",
    Pct_Faltantes_Test = "% Faltantes Test"
  ) %>%
  fmt_number(
    columns = c(Pct_Faltantes_Train, Pct_Faltantes_Test),
    decimals = 2
  ) %>%
  tab_options(
    table.font.size = 12,
    heading.align = "center"
  )

# Exportar tabla en HTML, PDF y PNG dentro de "Tablas y Graficos"
# HTML
gtsave(tabla_faltantes_pers, "Tablas y Graficos/7.Faltantes_Train_vs_Test_0a30.html")

# PDF
webshot2::webshot(
  "Tablas y Graficos/7.Faltantes_Train_vs_Test_0a30.html",
  "Tablas y Graficos/7.Faltantes_Train_vs_Test_0a30.pdf"
)

# PNG
gtsave(tabla_faltantes_pers, "Tablas y Graficos/7.Faltantes_Train_vs_Test_0a30.png")

# Mostrar en consola
tabla_faltantes_pers

```
```{r}
# Renombrar variables en ambos datasets (train y test)
renombrar_personas <- function(df) {
  df %>%
    rename(
      Parentesco_jefe = P6050,
      Edad = P6040,
      Sexo = P6020,
      Nivel_educativo = P6210,
      Actividad_Ocup = P6240
    )
}

train_personas2 <- renombrar_personas(train_personas)
test_personas2  <- renombrar_personas(test_personas)

# Variables comunes entre ambos datasets
vars_comunes_pers <- intersect(names(train_personas2), names(test_personas2))

# Calcular % de faltantes para TRAIN y TEST
calc_faltantes <- function(df, nombre_base) {
  df %>%
    select(all_of(vars_comunes_pers)) %>%
    summarise(across(everything(), ~mean(is.na(.)) * 100)) %>%
    pivot_longer(cols = everything(), names_to = "Variable", values_to = "Porcentaje_NA") %>%
    mutate(Base = nombre_base)
}

faltantes_train_pers <- calc_faltantes(train_personas2, "Train Personas")
faltantes_test_pers  <- calc_faltantes(test_personas2,  "Test Personas")

# Unir faltantes y clasificar categorías
faltantes_comp_pers <- left_join(
  faltantes_train_pers %>% rename(Pct_Faltantes_Train = Porcentaje_NA),
  faltantes_test_pers  %>% rename(Pct_Faltantes_Test = Porcentaje_NA),
  by = "Variable"
) %>%
  mutate(
    Categoria = case_when(
      Pct_Faltantes_Train == 0 & Pct_Faltantes_Test == 0 ~ "0% faltantes",
      (Pct_Faltantes_Train >= 1 & Pct_Faltantes_Train <= 30) |
        (Pct_Faltantes_Test >= 1 & Pct_Faltantes_Test <= 30) ~ "1% - 30%",
      TRUE ~ "Más del 30%"
    )
  )

# Preparar datos para el gráfico
faltantes_plot_pers <- faltantes_comp_pers %>%
  filter(Categoria %in% c("0% faltantes", "1% - 30%")) %>%
  select(Variable, Pct_Faltantes_Train, Pct_Faltantes_Test) %>%
  pivot_longer(
    cols = starts_with("Pct_Faltantes"),
    names_to = "Base",
    values_to = "Porcentaje_NA"
  ) %>%
  mutate(
    Base = ifelse(Base == "Pct_Faltantes_Train", "Train Personas", "Test Personas")
  )

# Crear gráfico comparativo
grafico_faltantes_pers <- ggplot(
  faltantes_plot_pers,
  aes(x = reorder(Variable, -Porcentaje_NA), y = Porcentaje_NA, fill = Base)
) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(
    aes(label = paste0(round(Porcentaje_NA, 1), "%")),
    position = position_dodge(width = 0.9),
    vjust = -0.25,
    size = 3
  ) +
  coord_flip() +
  labs(
    title = "Comparación de % de valores faltantes (0%-30%)\nTrain Personas vs Test Personas",
    x = "Variable",
    y = "% de valores faltantes"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.text.y = element_text(size = 9)
  ) +
  scale_fill_manual(
    values = c("Train Personas" = "lightyellow4", "Test Personas" = "#FFFF00")
  )

# Exportar gráfico a PDF y PNG dentro de la carpeta
# PDF
ggsave(
  filename = "Tablas y Graficos/8.Grafico_Faltantes_Train_vs_Test_Personas.pdf",
  plot = grafico_faltantes_pers,
  width = 10,
  height = 6
)

# PNG
ggsave(
  filename = "Tablas y Graficos/8.Grafico_Faltantes_Train_vs_Test_Personas.png",
  plot = grafico_faltantes_pers,
  width = 10,
  height = 6,
  dpi = 300
)

# Mostrar gráfico en consola
print(grafico_faltantes_pers)

```
### - Base de Entrenamiento Final

La base de datos de entrenamiento definitiva para las predicciones de pobreza a nivel de hogares es:
train_hogares_final

```{r}
# Seleccionar variables de hogares
train_hogares_sel <- train_hogares2 %>%
  select(id, Clase, Dominio, Tipo_vivienda, Nper, Depto, Pobre)

# Filtrar jefe de hogar en personas
jefes_hogar <- train_personas2 %>%
  filter(as.character(Parentesco_jefe) == "1") %>%  #Asegura tomar "1" en cualquier tipo
  select(id, Parentesco_jefe, Sexo, Edad, Nivel_educativo, Actividad_Ocup)

# Merge hogares + jefe de hogar
train_hogares_final <- train_hogares_sel %>%
  left_join(jefes_hogar, by = "id")

# Reescalar variable Clase en train_hogares_final
train_hogares_final <- train_hogares_final %>%
  mutate(
    Clase = as.numeric(as.character(Clase)),  # asegurar tipo numérico
    Clase = case_when(
      Clase %in% c(1, 2) ~ Clase,
      TRUE ~ NA_real_
    ),
    Clase = factor(
      Clase,
      levels = c(1, 2),
      labels = c(
        "Cabecera",
        "Resto (centros poblados y rural dispersa)"
      )
    )
  )

# Reescalar variable Nivel_educativo
train_hogares_final <- train_hogares_final %>%
  mutate(
    Nivel_educativo = case_when(
      Nivel_educativo == 9 ~ NA_real_,
      Nivel_educativo == 1 ~ 1,
      Nivel_educativo == 2 ~ 2,
      Nivel_educativo %in% c(3, 4, 5) ~ 3,
      Nivel_educativo == 6 ~ 4,
      TRUE ~ NA_real_
    ),
    Nivel_educativo = factor(
      Nivel_educativo,
      levels = c(1, 2, 3, 4),
      labels = c(
        "Ninguno",
        "Preescolar",
        "Máximo bachiller",
        "Superior o universitaria"
      ),
      ordered = TRUE
    )
  )

# Reescalar Parentesco_jefe
train_hogares_final <- train_hogares_final %>%
  mutate(
    Parentesco_jefe = case_when(
      Parentesco_jefe == 1 ~ 1,      # jefe
      TRUE ~ 2                       # todos los demás
    ),
    Parentesco_jefe = factor(
      Parentesco_jefe,
      levels = c(1, 2),
      labels = c("Jefe", "No jefe")
    )
  )

# Reescalar variable Sexo
train_hogares_final <- train_hogares_final %>%
  mutate(
    Sexo = case_when(
      Sexo %in% c(1, 2) ~ Sexo,   # valores válidos
      TRUE ~ NA_real_             # cualquier otro código → NA
    ),
    Sexo = factor(
      Sexo,
      levels = c(1, 2),
      labels = c("Hombre", "Mujer")
    )
  )


# Reescalar Actividad_ocup
train_hogares_final <- train_hogares_final %>%
  mutate(
    # Asegurar que sea numérica antes de recodificar
    Actividad_Ocup = as.numeric(as.character(Actividad_Ocup)),

    # Mantener solo valores válidos (1 a 6), los demás -> NA
    Actividad_Ocup = case_when(
      Actividad_Ocup %in% 1:6 ~ Actividad_Ocup,
      TRUE ~ NA_real_
    ),

    # Convertir a factor con etiquetas descriptivas
    Actividad_Ocup = factor(
      Actividad_Ocup,
      levels = c(1, 2, 3, 4, 5, 6),
      labels = c(
        "Trabajando",
        "Buscando trabajo",
        "Estudiando",
        "Oficios del hogar",
        "Incapacitado permanente",
        "Otra actividad"
      ),
      ordered = FALSE
    )
  )

# Reescalar variable Tipo_vivienda en train_hogares_final
train_hogares_final <- train_hogares_final %>%
  mutate(
    Tipo_vivienda = as.numeric(as.character(Tipo_vivienda)),  # asegurar tipo numérico
    Tipo_vivienda = case_when(
      Tipo_vivienda %in% 1:6 ~ Tipo_vivienda,  # mantener válidos
      TRUE ~ NA_real_
    ),
    # Re-codificar niveles uniendo las dos categorías de "Propia"
    Tipo_vivienda = case_when(
      Tipo_vivienda %in% c(1, 2) ~ 1,  # Propia pagada o pagando
      Tipo_vivienda == 3 ~ 2,          # Arriendo o subarriendo
      Tipo_vivienda == 4 ~ 3,          # Usufructo
      Tipo_vivienda == 5 ~ 4,          # Ocupante sin título
      Tipo_vivienda == 6 ~ 5,          # Otra
      TRUE ~ NA_real_
    ),
    Tipo_vivienda = factor(
      Tipo_vivienda,
      levels = c(1, 2, 3, 4, 5),
      labels = c(
        "Propia (pagada o pagando)",
        "Arriendo o subarriendo",
        "Usufructo",
        "Ocupante sin título",
        "Otra"
      ),
      ordered = TRUE
    )
  )



# Convertir Pobre
train_hogares_final$Pobre <- factor(train_hogares_final$Pobre,
                                    levels = c(0, 1),
                                    labels = c("NoPobre", "Pobre"))                                    
# Asegurar formato de variables categóricas
train_hogares_final <- train_hogares_final %>%
  mutate(
    across(c(Clase, Dominio, Tipo_vivienda, Parentesco_jefe, Sexo,
             Nivel_educativo, Actividad_Ocup), as.factor)
  )

# Revisar resultado
head(train_hogares_final)
```

Revision de datos faltantes en train hogares:
```{r}
# Calcular número y porcentaje de faltantes
faltantes_train_final <- train_hogares_final %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(
    cols = everything(),
    names_to = "Variable",
    values_to = "N_faltantes"
  ) %>%
  mutate(
    Pct_faltantes = round((N_faltantes / nrow(train_hogares_final)) * 100, 2)
  )

# Crear tabla con gt
tabla_faltantes_final <- faltantes_train_final %>%
  gt() %>%
  tab_header(title = "Valores faltantes en train_hogares_final") %>%
  cols_label(
    Variable = "Variable",
    N_faltantes = "N° Faltantes",
    Pct_faltantes = "% Faltantes"
  ) %>%
  fmt_number(
    columns = Pct_faltantes,
    decimals = 2
  )

# Exportar tabla en HTML, PDF y PNG

# HTML temporal
gtsave(tabla_faltantes_final, "Tablas y Graficos/9.Faltantes_train_hogares_final.html")

# PDF
webshot2::webshot(
  "Tablas y Graficos/9.Faltantes_train_hogares_final.html",
  "Tablas y Graficos/9.Faltantes_train_hogares_final.pdf"
)

# PNG
gtsave(tabla_faltantes_final, "Tablas y Graficos/9.Faltantes_train_hogares_final.png")

# Mostrar en consola
tabla_faltantes_final

```

### - Base de Prueba Final

La base de datos de prueba definitiva para las predicciones de pobreza a nivel de Hogares es:
test_hogares_final

```{r}
# Seleccionar variables de hogares
test_hogares_sel <- test_hogares2 %>%
  select(id, Clase, Dominio, Tipo_vivienda, Nper, Depto)

# Filtrar jefe de hogar en personas (numérico, factor o carácter)
jefes_hogar1 <- test_personas2 %>%
  filter(as.character(Parentesco_jefe) == "1") %>%  # se asegura de tomar "1" en cualquier tipo
  select(id, Parentesco_jefe, Sexo, Edad, Nivel_educativo, Actividad_Ocup)

# Merge hogares + jefe de hogar
test_hogares_final <- test_hogares_sel %>%
  left_join(jefes_hogar1, by = "id")


#Reescalar Clase de centro poblado
test_hogares_final <- test_hogares_final %>%
  mutate(
    Clase = as.numeric(as.character(Clase)),
    Clase = case_when(
      Clase %in% c(1, 2) ~ Clase,
      TRUE ~ NA_real_
    ),
    Clase = factor(
      Clase,
      levels = c(1, 2),
      labels = c(
        "Cabecera",
        "Resto (centros poblados y rural dispersa)"
      )
    )
  )


# Reescalar variable Nivel_educativo
test_hogares_final <- test_hogares_final %>%
  mutate(
    Nivel_educativo = case_when(
      Nivel_educativo == 9 ~ NA_real_,
      Nivel_educativo == 1 ~ 1,
      Nivel_educativo == 2 ~ 2,
      Nivel_educativo %in% c(3, 4, 5) ~ 3,
      Nivel_educativo == 6 ~ 4,
      TRUE ~ NA_real_
    ),
    Nivel_educativo = factor(
      Nivel_educativo,
      levels = c(1, 2, 3, 4),
      labels = c(
        "Ninguno",
        "Preescolar",
        "Máximo bachiller",
        "Superior o universitaria"
      ),
      ordered = TRUE
    )
  )

# Reescalar Parentesco_jefe
test_hogares_final <- test_hogares_final %>%
  mutate(
    Parentesco_jefe = case_when(
      Parentesco_jefe == 1 ~ 1,      # jefe
      TRUE ~ 2                       # todos los demás
    ),
    Parentesco_jefe = factor(
      Parentesco_jefe,
      levels = c(1, 2),
      labels = c("Jefe", "No jefe")
    )
  )

# Reescalar variable Sexo
test_hogares_final <- test_hogares_final %>%
  mutate(
    Sexo = case_when(
      Sexo %in% c(1, 2) ~ Sexo,   # valores válidos
      TRUE ~ NA_real_             # cualquier otro código → NA
    ),
    Sexo = factor(
      Sexo,
      levels = c(1, 2),
      labels = c("Hombre", "Mujer")
    )
  )

#Reescalar Activdad_Ocup
test_hogares_final <- test_hogares_final %>%
  mutate(
    # Asegurar que sea numérica antes de recodificar
    Actividad_Ocup = as.numeric(as.character(Actividad_Ocup)),

    # Mantener solo valores válidos (1 a 6), los demás -> NA
    Actividad_Ocup = case_when(
      Actividad_Ocup %in% 1:6 ~ Actividad_Ocup,
      TRUE ~ NA_real_
    ),

    # Convertir a factor con etiquetas descriptivas
    Actividad_Ocup = factor(
      Actividad_Ocup,
      levels = c(1, 2, 3, 4, 5, 6),
      labels = c(
        "Trabajando",
        "Buscando trabajo",
        "Estudiando",
        "Oficios del hogar",
        "Incapacitado permanente",
        "Otra actividad"
      ),
      ordered = FALSE
    )
  )

# Reescalar variable Tipo_vivienda en test_hogares_final
test_hogares_final <- test_hogares_final %>%
  mutate(
    Tipo_vivienda = as.numeric(as.character(Tipo_vivienda)),  # asegurar tipo numérico
    Tipo_vivienda = case_when(
      Tipo_vivienda %in% 1:6 ~ Tipo_vivienda,  # mantener válidos
      TRUE ~ NA_real_
    ),
    # Re-codificar niveles uniendo las dos categorías de "Propia"
    Tipo_vivienda = case_when(
      Tipo_vivienda %in% c(1, 2) ~ 1,  # Propia pagada o pagando
      Tipo_vivienda == 3 ~ 2,          # Arriendo o subarriendo
      Tipo_vivienda == 4 ~ 3,          # Usufructo
      Tipo_vivienda == 5 ~ 4,          # Ocupante sin título
      Tipo_vivienda == 6 ~ 5,          # Otra
      TRUE ~ NA_real_
    ),
    Tipo_vivienda = factor(
      Tipo_vivienda,
      levels = c(1, 2, 3, 4, 5),
      labels = c(
        "Propia (pagada o pagando)",
        "Arriendo o subarriendo",
        "Usufructo",
        "Ocupante sin título",
        "Otra"
      ),
      ordered = TRUE
    )
  )

# Asegurar formato de variables categóricas
test_hogares_final <- test_hogares_final %>%
  mutate(
    across(c(Clase, Dominio, Tipo_vivienda, Parentesco_jefe, Sexo,
             Nivel_educativo, Actividad_Ocup), as.factor)
  )

# Revisar resultado
head(test_hogares_final)
```

Revision de datos faltantes test hogares:

```{r}
# Calcular número y porcentaje de faltantes
faltantes_test_final <- test_hogares_final %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(
    cols = everything(),
    names_to = "Variable",
    values_to = "N_faltantes"
  ) %>%
  mutate(
    Pct_faltantes = round((N_faltantes / nrow(test_hogares_final)) * 100, 2)
  )

# Crear tabla con gt
tabla_faltantes_test_final <- faltantes_test_final %>%
  gt() %>%
  tab_header(title = "Valores faltantes en test_hogares_final") %>%
  cols_label(
    Variable = "Variable",
    N_faltantes = "N° Faltantes",
    Pct_faltantes = "% Faltantes"
  ) %>%
  fmt_number(
    columns = Pct_faltantes,
    decimals = 2
  )

# Exportar tabla en HTML, PDF y PNG

# HTML temporal (necesario para generar PDF)
gtsave(tabla_faltantes_test_final, "Tablas y Graficos/10.Faltantes_test_hogares_final.html")

# PDF
webshot2::webshot(
  "Tablas y Graficos/10.Faltantes_test_hogares_final.html",
  "Tablas y Graficos/10.Faltantes_test_hogares_final.pdf"
)

# PNG
gtsave(tabla_faltantes_test_final, "Tablas y Graficos/10.Faltantes_test_hogares_final.png")

# Mostrar en pantalla
tabla_faltantes_test_final

```

Se evidencia un valor faltante en la variable Actividad_Ocup para cada base final, por lo que se procede a imputar con la moda:

```{r}
# Función robusta: imputar por moda con impresión clara por base
imputar_moda <- function(df, variable, nombre_base = "Desconocida") {
  var <- df[[variable]]
  
  # Calcular NA antes
  n_na_antes <- sum(is.na(var))
  
  # Calcular la moda (valor más frecuente, excluyendo NA)
  moda <- names(sort(table(var), decreasing = TRUE))[1]
  
  cat("Base:", nombre_base, "\n")
  cat("Variable:", variable, "\n")
  cat(" - NAs antes de imputar:", n_na_antes, "\n")
  cat(" - Moda usada:", moda, "\n")
  
  # Copiar el data frame (para seguridad)
  df2 <- df
  
  # Imputar manteniendo la clase
  if (is.factor(var)) {
    niveles <- levels(var)
    ordenado <- is.ordered(var)
    
    var_char <- as.character(var)
    var_char[is.na(var_char)] <- moda
    
    df2[[variable]] <- factor(var_char, levels = niveles, ordered = ordenado)
  } else {
    var_temp <- var
    var_temp[is.na(var_temp)] <- moda
    df2[[variable]] <- var_temp
  }
  
  # Calcular NA después
  n_na_despues <- sum(is.na(df2[[variable]]))
  
  cat(" - NAs después de imputar:", n_na_despues, "\n")
  cat("------------------------------------------------------------\n\n")
  
  return(df2)
}

# Aplicar imputación a TRAIN y TEST con identificación clara

train_hogares_final <- train_hogares_final %>%
  imputar_moda("Actividad_Ocup", nombre_base = "TRAIN Hogares Final") %>%
  imputar_moda("Nivel_educativo", nombre_base = "TRAIN Hogares Final")

test_hogares_final <- test_hogares_final %>%
  imputar_moda("Actividad_Ocup", nombre_base = "TEST Hogares Final") %>%
  imputar_moda("Nivel_educativo", nombre_base = "TEST Hogares Final")

# Resumen final
cat("\n RESUMEN FINAL DE NAs:\n")
cat("TRAIN - Actividad_Ocup:", sum(is.na(train_hogares_final$Actividad_Ocup)), "\n")
cat("TRAIN - Nivel_educativo:", sum(is.na(train_hogares_final$Nivel_educativo)), "\n")
cat("TEST  - Actividad_Ocup:", sum(is.na(test_hogares_final$Actividad_Ocup)), "\n")
cat("TEST  - Nivel_educativo:", sum(is.na(test_hogares_final$Nivel_educativo)), "\n")

```
```{r}
# Crear diccionario automático desde el dataset
dicc_final <- tibble(
  Variable = names(train_hogares_final),
  Descripcion = "Descripción pendiente"
) %>%
  mutate(
    Descripcion = case_when(
      Variable == "id" ~ "Llave única del hogar",
      Variable == "Clase" ~ "Clase de centro poblado: 1. Cabecera; 2. Resto (centros poblados y rural dispersa)",
      Variable == "Dominio" ~ "Dominio geográfico: áreas metropolitanas, cabeceras y resto",
      Variable == "Tipo_vivienda" ~ "Tipo de vivienda: a. Propia (Pagada o Pagando), b. Arriendo/subarriendo, c. Usufructo, d. Ocupante sin título, e. Otra",
      Variable == "Nper" ~ "Número de personas en el hogar",
      Variable == "Depto" ~ "Departamento de residencia",
      Variable == "Pobre" ~ "1 = Pobre ; 0 = No pobre (solo en base de entrenamiento)",
      Variable == "Parentesco_jefe" ~ "Parentesco con el jefe de hogar (1 = jefe, otros = distintos roles)",
      Variable == "Sexo" ~ "Sexo del jefe de hogar (1 = Hombre, 2 = Mujer)",
      Variable == "Edad" ~ "Edad del jefe de hogar (en años)",
      Variable == "Nivel_educativo" ~ "Nivel educativo alcanzado por el jefe de hogar:\n a. Ninguno, b. Preescolar, c.Máximo Bachiller , d. Superior o universitaria",
      Variable == "Actividad_Ocup" ~ "Condición de actividad u ocupación del jefe de hogar:\n a. Trabajando, b. Buscando trabajo, c. Estudiando, d. Oficios del hogar, e. Incapacitado permanente, f. Otra actividad",
      TRUE ~ Descripcion
    )
  )

# Crear tabla gt
dicc_final <- dicc_final %>%
  gt() %>%
  tab_header(
    title = "Diccionario de Variables en base de entrenamiento y de prueba"
  ) %>%
  cols_label(
    Variable = "Variable",
    Descripcion = "Descripción"
  )


# Exportar tabla en HTML, PDF y PNG
# HTML
gtsave(dicc_final, "Tablas y Graficos/11.Diccionario_train_hogares_final.html")

# PDF
webshot2::webshot(
  "Tablas y Graficos/11.Diccionario_train_hogares_final.html",
  "Tablas y Graficos/11.Diccionario_train_hogares_final.pdf"
)

# PNG
gtsave(dicc_final, "Tablas y Graficos/11.Diccionario_train_hogares_final.png")

# Mostrar en consola
dicc_final

```

### 2.2. Estadísticas descriptivas
Tabla de estadisticas descriptivas para las dos bases de hogares:
   
```{r}
# Función para obtener estadísticas descriptivas
obtener_estadisticas <- function(df, nombre_base) {
  
  # Excluir variables no relevantes
  datos <- df %>% select(-id, -Dominio, -Depto)
  
  # Variables numéricas
  num_stats <- datos %>%
    select(where(is.numeric)) %>%
    summarise(across(
      everything(),
      list(
        Media = ~mean(.x, na.rm = TRUE),
        DesvEst = ~sd(.x, na.rm = TRUE),
        Min = ~min(.x, na.rm = TRUE),
        Q1 = ~quantile(.x, 0.25, na.rm = TRUE),
        Mediana = ~median(.x, na.rm = TRUE),
        Q3 = ~quantile(.x, 0.75, na.rm = TRUE),
        Max = ~max(.x, na.rm = TRUE),
        NAs = ~sum(is.na(.x))
      ),
      .names = "{.col}.{.fn}"
    ))
  
  # Reorganizar en formato largo
  num_stats_long <- num_stats %>%
    pivot_longer(
      cols = everything(),
      names_to = c("Variable", ".value"),
      names_sep = "\\."
    )
  
  # Variables categóricas
  cat_vars <- datos %>%
    select(where(~is.character(.x) || is.factor(.x)))
  
  if (ncol(cat_vars) > 0) {
    cat_stats <- data.frame(
      Variable = names(cat_vars),
      Unicos = sapply(cat_vars, function(x) length(unique(x))),
      NAs = sapply(cat_vars, function(x) sum(is.na(x)))
    )
  } else {
    cat_stats <- NULL
  }
  
  # Combinar ambas
  estadisticas <- bind_rows(num_stats_long, cat_stats) %>%
    mutate(Base = nombre_base)
  
  return(estadisticas)
}

# Calcular estadísticas para Train y Test
stats_train <- obtener_estadisticas(train_hogares_final, "Train Hogares Final")
stats_test  <- obtener_estadisticas(test_hogares_final,  "Test Hogares Final")

# Unir ambas bases en una sola tabla
estadisticas_hogares <- bind_rows(stats_train, stats_test)

# Crear tabla única con subtítulos por base
tabla_estadisticas <- estadisticas_hogares %>%
  gt(groupname_col = "Base") %>%   #Agrupa por base (subtítulos)
  tab_header(
    title = "Estadísticas Descriptivas: Train y Test Hogares Final"
  ) %>%
  cols_label(
    Variable = "Variable",
    Media = "Media",
    DesvEst = "Desv. Estándar",
    Min = "Mínimo",
    Q1 = "Q1",
    Mediana = "Mediana",
    Q3 = "Q3",
    Max = "Máximo",
    NAs = "N° NAs",
    Unicos = "N° Únicos"
  ) %>%
  fmt_number(
    columns = c(Media, DesvEst, Min, Q1, Mediana, Q3, Max),
    decimals = 2
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", color = "white"),
    locations = cells_row_groups()
  ) %>%
  tab_style(
    style = cell_fill(color = "gray40"),
    locations = cells_row_groups()
  ) %>%
  opt_table_font(font = list(google_font("Roboto"))) %>%
  tab_options(
    row_group.as_column = FALSE,    # subtítulo cada base
    table.font.size = px(13),
    table.width = pct(100)
  )

# Exportar tabla a HTML, PDF y PNG
dir.create("Tablas y Graficos", showWarnings = FALSE)

# HTML
gtsave(tabla_estadisticas, "Tablas y Graficos/12.Estadisticas_Descriptivas_Train_y_Test.html")

# PDF
webshot2::webshot(
  "Tablas y Graficos/12.Estadisticas_Descriptivas_Train_y_Test.html",
  "Tablas y Graficos/12.Estadisticas_Descriptivas_Train_y_Test.pdf"
)

# PNG
gtsave(tabla_estadisticas, "Tablas y Graficos/12.Estadisticas_Descriptivas_Train_y_Test.png")

# Mostrar en pantalla
tabla_estadisticas

```



## 3. Modelos y Resultados

```{r}
train_hogares_final
test_hogares_final
```


# ELASTIC NET
```{r}
str(train_hogares_final)
```


# CARTS

El modelo CART utiliza un árbol de decisión binario para predecir la condición de pobreza de los hogares.
Divide los datos en grupos cada vez más homogéneos según variables como tipo de vivienda, nivel educativo, número de personas y ocupación del jefe del hogar. Se tomaron los siguientos pasos

   - Se aseguró la consistencia de los niveles de la variable *Dominio* entre los conjuntos de entrenamiento y prueba.

 **Preparación de la receta**
   - Se creó una receta con la función `recipe()` para preprocesar los datos:
   - Conversión de variables categóricas a dummies (`step_dummy()`).
   - Balanceo de clases con **SMOTE** (`step_smote()`).
   - Estandarización de variables numéricas (`step_center()` y `step_scale()`).

 **Definición del control de entrenamiento**
   - Se configuró una validación cruzada (`cv = 5`).
   - Se incluyó una función de resumen (`fiveStats`) que calcula el **ROC** y otras medidas de desempeño.

**Entrenamiento del modelo CART**
   - Se utilizó el método `"rpart"` buscando el hiperparámetros (`cp`) desde 0.001 hasta 0.02.
   - La métrica de optimización fue el **ROC AUC**.

**Evaluación del modelo**
   - Se estimó el **F1-score** para todos los posibles umbrales de decisión.
   - Se identificó el umbral óptimo que maximiza el F1.

**Poda del árbol y visualización**
   - Se podó el árbol con el parámetro `cp` óptimo.
   - Se graficó el árbol podado.

**Predicción sobre el conjunto de prueba**
   - Se calcularon probabilidades de pobreza.
   - Se aplicó el umbral óptimo para clasificar hogares en Pobre y NoPobres
   - Se exportaron las predicciones a un archivo `.csv` y el modelo a un archivo `.rds`.


```{r}

install.packages("ROCR")
install.packages("rpart.plot")
library(caret)
library(rpart)
library(rpart.plot)
library(dplyr)
library(recipes)
library(themis)
library(ROCR)

#Aseguramos que los niveles sean los mismos en Dominio debido a que esta 
#variable no se encuentra en test

test_hogares_final$Dominio <- factor(test_hogares_final$Dominio, 
                                     levels = levels(train_hogares_final$Dominio))

#Semilla
set.seed(123)

# Creamos receta para balancear
receta_cart <- recipe(
  Pobre ~ Clase + Dominio + Tipo_vivienda + Nper +
    Sexo + Edad + Nivel_educativo + Actividad_Ocup,
  data = train_hogares_final
) %>%
  step_dummy(all_nominal_predictors()) %>%  # Convierte factores a dummies
  step_smote(Pobre) %>%                     # Balancea con SMOTE
  step_center(all_predictors()) %>%         # Centra variables numéricas
  step_scale(all_predictors())              # Escala variables numéricas

# Función para contralar
fiveStats <- function(...) {
  c(
    twoClassSummary(...),
    defaultSummary(...)
  )
}


# Validación cruzada
ctrl <- trainControl(
  method = "cv", #Validación cruzada
  number = 5, #particiones
  summaryFunction = fiveStats, #Función de metricas anterior
  classProbs = TRUE, #probabilidades de clase
  verboseIter = TRUE,
  savePredictions = "final" #guarda predicciones
)


# Entrenamiento del modelo CART
modelo_cart<- train(
  receta_cart,
  data = train_hogares_final,
  method = "rpart", #Metodo cart
  trControl = ctrl,
  tuneGrid = expand.grid(cp = seq(0.001, 0.02, 0.001)), #valores de cp
  metric = "ROC"  #Métrica  AUC de ROC
)

modelo_cart

# Extraer predicciones de caret
preds <- modelo_cart$pred


# Crear el objeto de predicción para ROC
pred_rocr <- prediction(preds$Pobre, preds$obs)

# Calcular el F1-score a lo largo de todos los posibles umbrales
f1 <- performance(pred_rocr, "f")

# Extraemos el índice del mejor F1
best_index <- which.max(slot(f1, "y.values")[[1]])

# Extraemos el valor de F1 Máximo
best_f1 <- slot(f1, "y.values")[[1]][best_index]
best_cutoff <- slot(f1, "x.values")[[1]][best_index]

cat("Mejor cutoff):", round(best_cutoff, 3), "\n")
cat("F1 máximo:", round(best_f1, 3), "\n")


# Poda del arbol
cp_optimo <- modelo_cart$bestTune$cp
arbol_prunin <- prune(modelo_cart$finalModel, cp = cp_optimo)

#Visualización del arbol

# Asegurar carpeta
dir.create("Tablas y Graficos", showWarnings = FALSE)


arbol_podado <- prp(arbol_prunin, under = TRUE, branch.lty = 2, yesno = 1, faclen = 0, varlen = 15, box.palette = "-RdYlGn", main = "Árbol CART Podado")

png("Tablas y Graficos/arbol_podado.png", width = 2000, height = 1400, res = 150)
prp(arbol_prunin, 
    under = TRUE, branch.lty = 2, yesno = 1, faclen = 0, varlen = 15, 
    box.palette = "-RdYlGn", main = "Árbol CART Podado")
dev.off()

pdf("Tablas y Graficos/arbol_podado.pdf", width = 12, height = 9)
prp(arbol_prunin, 
    under = TRUE, branch.lty = 2, yesno = 1, faclen = 0, varlen = 15, 
    box.palette = "-RdYlGn", main = "Árbol CART Podado")
dev.off()


# Predicciones:
pred_cart<- predict(modelo_cart, newdata = test_hogares_final, type = "prob")

test_hogares_final$Prob_Pobre <- pred_cart[, "Pobre"] #Pobre es la clase positiva
test_hogares_final$pobre <- ifelse(test_hogares_final$Prob_Pobre >= best_cutoff, 1, 0) 

Prediccion_cart <- test_hogares_final |> select(id, pobre)
head(Prediccion_cart)

# Guedamos el archivo
saveRDS(modelo_cart, file = "CART_cp_0_005.rds")
write.csv(Prediccion_cart, "CART_cp_0_005.csv", row.names = FALSE)

```

Adicionalmente traemos las mejores métricas del modelo CART para su visualización


```{r}


# best_f1, best_cutoff, modelo_cart
mejor_cp <- modelo_cart$bestTune$cp
mejor_roc <- max(modelo_cart$results$ROC)
mejor_acc <- modelo_cart$results$Accuracy[which.max(modelo_cart$results$ROC)]
mejor_sens <- modelo_cart$results$Sens[which.max(modelo_cart$results$ROC)]
mejor_spec <- modelo_cart$results$Spec[which.max(modelo_cart$results$ROC)]

# --- Crear data frame resumen con grupos de métricas ---
resumen_modelo <- data.frame(
  Base = c(rep("Validación Cruzada", 5), rep("Optimización de Umbral", 2)),
  Métrica = c("Mejor CP", "ROC", "Accuracy", "Sensibilidad", "Especificidad",
              "F1 máximo estimado", "Mejor umbral (cutoff)"),
  Valor = c(mejor_cp, mejor_roc, mejor_acc, mejor_sens, mejor_spec, best_f1, best_cutoff)
)

# Crear tabla con formato 
tabla_modelo_cart <- resumen_modelo %>%
  gt(groupname_col = "Base") %>%
  tab_header(
    title = "Resultados del Modelo CART"
  ) %>%
  cols_label(
    Métrica = "Métrica del modelo",
    Valor = "Valor estimado"
  ) %>%
  fmt_number(
    columns = Valor,
    decimals = 3
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", color = "white"),
    locations = cells_row_groups()
  ) %>%
  tab_style(
    style = cell_fill(color = "gray40"),
    locations = cells_row_groups()
  ) %>%
  opt_table_font(font = list(google_font("Roboto"))) %>%
  tab_options(
    table.font.size = px(14),
    table.width = pct(80),
    column_labels.font.weight = "bold",
    data_row.padding = px(6)
  ) %>%
  # --- Nota al pie aclaratoria ---
  tab_source_note(
    source_note = md(
      "**Nota:** Las métricas se estiman mediante *validación cruzada* sobre el conjunto de entrenamiento.  
      No se calculan sobre el conjunto de test porque este no contiene la variable sw pobreza."
    )
  )

# --- Exportar tabla a HTML, PDF y PNG ---
dir.create("Tablas y Graficos", showWarnings = FALSE)

# HTML
gtsave(tabla_modelo_cart, "Tablas y Graficos/13.Resultados_Modelo_CART.html")

# PDF
webshot2::webshot(
  "Tablas y Graficos/13.Resultados_Modelo_CART.html",
  "Tablas y Graficos/13.Resultados_Modelo_CART.pdf"
)

# PNG
gtsave(tabla_modelo_cart, "Tablas y Graficos/13.Resultados_Modelo_CART.png")


tabla_modelo_cart
```

# BOOSTING

En este análisis, se desarrolló un modelo de clasificación basado en XGBoost (Extreme Gradient Boosting) con el objetivo de estimar la probabilidad de que un hogar sea pobre. Este enfoque combina técnicas de preprocesamiento, validación cruzada y optimización de hiperparámetros para obtener un modelo robusto y con buen poder predictivo.

 **Preparación de la receta**
   - Se creó una receta con la función `recipe()` para preprocesar los datos:
   - Conversión de variables categóricas a dummies (`step_dummy()`).
   - Balanceo de clases con **SMOTE** (`step_smote()`).
   - Estandarización de variables numéricas (`step_center()` y `step_scale()`).

 **Definición del control de entrenamiento**
   - Se configuró una validación cruzada (`cv = 5`).
   - Se incluyó una función de resumen (`fiveStats`) que calcula el **ROC** y otras medidas de desempeño.

**Creación del grid de hiperparámetros**
   - Combinación óptima que maximice la métrica ROC, equilibrando el sesgo y la varianza del modelo.
   
**Creación del grid de hiperparámetros**
   - Se entrena el modelo usando XGBoost
   - Se realiza una paralelización reduce el tiempo de cómputo al evaluar simultáneamente distintas combinaciones del grid.
   
**Evaluación del modelo**
   - Se inspeccionan los resultados del modelo, visualizando cómo varía la métrica ROC en función de los hiperparámetros. 
   - El modelo con mejor desempeño será aquel que logre la mayor capacidad de discriminación entre hogares pobres y no pobres.



```{r}


library(xgboost)
library(doParallel)

# Luego la receta SIN step_smote()
receta_xgb <- recipe(
  Pobre ~ Clase + Dominio + Tipo_vivienda + Nper +
    Sexo + Edad + Nivel_educativo + Actividad_Ocup,
  data = train_hogares_final
) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_smote(Pobre) %>%  
  step_center(all_predictors()) %>%
  step_scale(all_predictors())

# =========================================
# 🎛️ Control de entrenamiento
# =========================================
ctrl_xgb <- trainControl(
  method = "cv",
  number = 5,
  summaryFunction = twoClassSummary,  # o f1_summary si defines tu propia métrica
  classProbs = TRUE,
  verboseIter = TRUE,
  savePredictions = "final",
  allowParallel = TRUE
)


#  Grid de hiperparámetros XGBoost

grid_xgb <- expand.grid(
  nrounds = c(300),
  max_depth = c(4, 6),
  eta = c(0.05, 0.1),
  gamma = c(0, 1),
  colsample_bytree = c(0.8),
  min_child_weight = c(1, 3),
  subsample = c(0.8)
)

grid_xgb

cl <- makeCluster(parallel::detectCores() - 1)
registerDoParallel(cl)

# Entrenamiento del modelo XGBoost Boosting
registerDoSEQ()   # Desactiva paralelo

modelo_xgb <- train(
  receta_xgb,
  data = train_hogares_final,
  method = "xgbTree",
  trControl = ctrl,
  tuneGrid = grid_xgb,
  metric = "ROC"
)

# Resultados del modelo

modelo_xgb
varImp(modelo_xgb)


```
Aquí se evalúan y aplican los resultados del modelo XGBoost previamente entrenado, con el objetivo de identificar el umbral de decisión óptimo que maximiza el desempeño del modelo según la métrica F1-score, y posteriormente generar las predicciones finales sobre el conjunto de prueba.

**Evaluación del modelo con F1-score**
  - se construyó un objeto de predicción a partir de los resultados de la validación cruzada interna (modelo_xgb$pred).
  - Evaluación de la calidad del modelo en distintos umbrales de probabilidad (cutoffs) usando la librería ROCR.

**Generación de predicciones sobre el conjunto de prueba**
  - Con el modelo ajustado, se estimaron las probabilidades de pobreza para cada hogar del conjunto de test.
  - Aplicando el umbral óptimo, se generó la variable binaria pobre, que toma el valor 1 si la probabilidad de ser pobre es igual o mayor al cutoff, y 0 en caso contrario.
  
**Exportación de resultados**
  - Finalmente, se preparó un archivo de salida con los identificadores (id) y la predicción binaria (pobre).
  - Para asegurar trazabilidad y facilitar la identificación de los resultados, se incluyó en el nombre del archivo información sobre los hiperparámetros óptimos del modelo y el valor del cutoff.


```{r}
# Crear objeto con las predicciones del CV interno
pred <- prediction(modelo_xgb$pred$Pobre, modelo_xgb$pred$obs)

# Calcular F1 en todos los posibles puntos de corte
perf <- performance(pred, "f")

# Encontrar el índice del F1 máximo
best_f1_index <- which.max(slot(perf, "y.values")[[1]])

# Extraer el cutoff correspondiente
best_cutoff <- slot(perf, "x.values")[[1]][best_f1_index]
best_f1 <- slot(perf, "y.values")[[1]][best_f1_index]

cat("Mejor cutoff encontrado:", round(best_cutoff, 3), "\n")
cat("F1 máximo obtenido:", round(best_f1, 3), "\n")

best_cutoff <- 0.343

# Predicciones en test
pred_prob <- predict(modelo_xgb, newdata = test_hogares_final, type = "prob")

# Generar variable binaria Pobre/No Pobre
test_hogares_final <- test_hogares_final %>%
  mutate(
    Prob_Pobre = pred_prob[, "Pobre"],
    pobre = ifelse(Prob_Pobre >= best_cutoff, 1, 0)
  )

#  Crear archivo de envío
predict_boosting <- test_hogares_final %>%
  select(id, pobre)


# Guardar modelo y predicciones


#  Extraer hiperparámetros del mejor modelo
params <- modelo_xgb$bestTune
param_str <- sprintf("n%s_md%s_eta%s_sub%s_col%s",
                     params$nrounds,
                     params$max_depth,
                     params$eta,
                     params$subsample,
                     params$colsample_bytree)

# ️ Nombre base del archivo
file_tag <- paste0("XGB_", param_str, "_SMOTE_CV5_cut", best_cutoff, "_")

#  Guardar modelo y predicciones
saveRDS(modelo_xgb, paste0(file_tag, ".rds"))
write.csv(predict_boosting, paste0(file_tag, ".csv"), row.names = FALSE)

install.packages("DiagrammeR")
library(DiagrammeR)
tree_plot <- xgboost::xgb.plot.tree(
  model = modelo_xgb$finalModel,
  trees = 1:2,
  plot_width = 1000,
  plot_height = 500)
tree_plot
```


```{r}

# Crear tabla de resumen con las principales métricas del modelo
resultados_xgb <- tibble::tibble(
  Métrica = c("Número de muestras", 
              "Número de predictores", 
              "Número de clases", 
              "Pasos de preprocesamiento",
              "Método de validación", 
              "Tamaño promedio de muestra en CV",
              "Mejor combinación de hiperparámetros",
              "ROC (AUC) promedio",
              "Sensibilidad promedio",
              "Especificidad promedio",
              "Accuracy promedio",
              "Kappa promedio"),
  Valor = c("164,960",
            "14",
            "2 (NoPobre, Pobre)",
            "novel, dummy, zv, smote, center, scale",
            "Validación Cruzada (5 folds)",
            "≈131,968 observaciones por fold",
            "nrounds = 300, max_depth = 6, eta = 0.1, gamma = 0, colsample_bytree = 0.8, min_child_weight = 3, subsample = 0.8",
            "0.808",
            "0.886",
            "0.475",
            "0.804",
            "0.371")
)

# Crear tabla con estilo profesional
tabla_xgb <- resultados_xgb %>%
  gt() %>%
  tab_header(
    title = md("**Resultados del Modelo XGBoost (eXtreme Gradient Boosting)**"),
    subtitle = "Entrenado con balanceo SMOTE y validación cruzada de 5 particiones"
  ) %>%
  cols_label(
    Métrica = "Métrica del modelo",
    Valor = "Valor estimado"
  ) %>%
  fmt_number(
    columns = Valor,
    decimals = 3,
    rows = 8:12
  ) %>%
  tab_style(
    style = cell_text(weight = "bold", color = "white"),
    locations = cells_title(groups = "title")
  ) %>%
  tab_style(
    style = cell_fill(color = "gray30"),
    locations = cells_title(groups = "title")
  ) %>%
  opt_table_font(font = list(google_font("Roboto"))) %>%
  tab_options(
    table.font.size = px(13),
    table.width = pct(100)
  )

# Mostrar tabla
tabla_xgb

# --- Exportar tabla a HTML, PDF y PNG ---
dir.create("Tablas y Graficos", showWarnings = FALSE)

# HTML
gtsave(tabla_xgb, "Tablas y Graficos/13.Resultados_Modelo_BOOSTING.html")

# PDF
webshot2::webshot(
  "Tablas y Graficos/13.Resultados_Modelo_BOOSTING.html",
  "Tablas y Graficos/13.Resultados_Modelo_BOOSTING.pdf"
)

# PNG
gtsave(tabla_xgb, "Tablas y Graficos/13.Resultados_Modelo_BOOSTING.png")


```


# Boosting ensamblado con CART

```{r}
# ============================================================
# 📦 LIBRERÍAS
# ============================================================
library(caret)
library(dplyr)
library(doParallel)
library(ROCR)
library(yardstick)
library(recipes)
library(themis)
library(ggplot2)
library(forcats)

#semilla
set.seed(1011)

# Preprocesamiento

train_hogares_final %>%
  mutate(Tipo_vivienda_simplificado = fct_collapse(Tipo_vivienda,
    Propia = c("propia (pagada o pagando)"),
    Alquilada = c("arriendo/subarriendo"),
    NoPropia = c("usufructo", "ocupante sin título", "otra")
  ))

test_hogares_final %>%
  mutate(Tipo_vivienda_simplificado = fct_collapse(Tipo_vivienda,
    Propia = c("propia (pagada o pagando)"),
    Alquilada = c("arriendo/subarriendo"),
    NoPropia = c("usufructo", "ocupante sin título", "otra")
  ))

# Agrupar niveles poco frecuentes para evitar dummies excesivos
train_hogares_final <- train_hogares_final %>%
  mutate(
    Dominio = fct_lump(Dominio, n = 20),
    Nivel_educativo = fct_lump(Nivel_educativo, n = 10),
    Actividad_Ocup = fct_lump(Actividad_Ocup, n = 10)
  )

test_hogares_final <- test_hogares_final %>%
  mutate(
    Dominio = fct_lump(Dominio, n = 20),
    Nivel_educativo = fct_lump(Nivel_educativo, n = 10),
    Actividad_Ocup = fct_lump(Actividad_Ocup, n = 10)
  )

#  Crear variables adicionales (no lineales e interacciones)
train_hogares_final <- train_hogares_final %>%
  mutate(
    Edad2 = Edad^2,
    log_Nper = log1p(Nper),
    Edad_x_Nper = Edad * Nper
  )

test_hogares_final <- test_hogares_final %>%
  mutate(
    Edad2 = Edad^2,
    log_Nper = log1p(Nper),
    Edad_x_Nper = Edad * Nper
  )


# Receta
receta_xgb <- recipe(
  Pobre ~ Clase + Dominio + Tipo_vivienda + Nper + Sexo +
    Edad + Edad2 + log_Nper + Edad_x_Nper +
    Nivel_educativo + Actividad_Ocup,
  data = train_hogares_final
) %>%
  step_novel(all_nominal_predictors()) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors())

cat(" reparando la receta...\n")
receta_prep <- prep(receta_xgb)
train_ready <- bake(receta_prep, new_data = train_hogares_final)
test_ready  <- bake(receta_prep, new_data = test_hogares_final)
cat(" receta lista.\n")

# Balanceo de clases
pos_weight <- (sum(train_ready$Pobre == "NoPobre") /
               sum(train_ready$Pobre == "Pobre"))
cat(" scale_pos_weight =", round(pos_weight, 2), "\n")


#  control de entrenamiento
ctrl_xgb <- trainControl(
  method = "cv",
  number = 3,                 # 3 folds
  summaryFunction = twoClassSummary,
  classProbs = TRUE,
  verboseIter = TRUE,
  savePredictions = "final"
)


#  Grid de hiperparamentros

grid_xgb <- expand.grid(
  nrounds = c(400, 600),
  max_depth = c(4, 5),
  eta = c(0.05, 0.08),
  gamma = c(0, 1),
  colsample_bytree = 0.8,
  min_child_weight = 2,
  subsample = 0.8
)


#  Paralelización y entrenamiento

cl <- makeCluster(parallel::detectCores() - 1)
registerDoParallel(cl)


modelo_xgb <- train(
  x = select(train_ready, -Pobre),
  y = train_ready$Pobre,
  method = "xgbTree",
  trControl = ctrl_xgb,
  tuneGrid = grid_xgb,
  metric = "ROC",
  weights = ifelse(train_ready$Pobre == "Pobre", pos_weight, 1)
)
stopCluster(cl)
registerDoSEQ()



# MODELO CART (para ensemble)

modelo_cart <- train(
  Pobre ~ ., data = train_ready,
  method = "rpart",
  trControl = trainControl(method = "cv", number = 3, classProbs = TRUE),
  tuneGrid = expand.grid(cp = seq(0.001, 0.01, 0.002)))

#  Obtener los nombres de parámetros del bestTune (para filtrar correctamente)
bestTune_xgb <- modelo_xgb$bestTune
tune_cols <- names(bestTune_xgb)

#  Filtrar predicciones OOF EXACTAS para el bestTune
pred_xgb_oof <- modelo_xgb$pred %>%
  filter(!!!rlang::syms(tune_cols) == bestTune_xgb) 
if (nrow(pred_xgb_oof) == 0) {
  pred_xgb_oof <- modelo_xgb$pred
  for (nm in tune_cols) {
    pred_xgb_oof <- pred_xgb_oof %>% filter(.data[[nm]] == bestTune_xgb[[nm]])
  }
}

# Asegurarnos que modelo_cart tiene OOF preds en el mismo orden/index
if (!"rowIndex" %in% names(pred_xgb_oof)) {
  stop("No hay 'rowIndex' en predicciones OOF de XGB. No podemos alinear ensemble OOF.")
}
# Obtener OOF preds de CART (filtradas por su bestTune)
bestTune_cart <- modelo_cart$bestTune
tune_cols_cart <- names(bestTune_cart)

pred_cart_oof <- modelo_cart$pred
for (nm in tune_cols_cart) {
  pred_cart_oof <- pred_cart_oof %>% filter(.data[[nm]] == bestTune_cart[[nm]])
}

# Alinear por rowIndex (o por obs si no hay rowIndex)
# Usamos rowIndex para asegurar correspondencia de filas OOF
oof_ens <- pred_xgb_oof %>%
  select(rowIndex, obs, xgb_prob = Pobre) %>%
  left_join(
    pred_cart_oof %>% select(rowIndex, cart_prob = Pobre),
    by = "rowIndex"
  )

# Si cart_prob tiene NA (no hay pred para algunos rowIndex), intentar alinear por obs order
if (any(is.na(oof_ens$cart_prob))) {
  warning("Algunos rowIndex no alinearon por rowIndex; intentando alinear por orden dentro de folds.")
  # Fallback: simple join por rowIndex falló; intentar por positions (solo si longitudes coinciden)
  if (nrow(pred_xgb_oof) == nrow(pred_cart_oof)) {
    oof_ens <- tibble(
      rowIndex = pred_xgb_oof$rowIndex,
      obs = pred_xgb_oof$obs,
      xgb_prob = pred_xgb_oof$Pobre,
      cart_prob = pred_cart_oof$Pobre
    )
  } else {
    stop("No fue posible alinear OOF de XGB y CART. Revisa modelos y predicciones OOF.")
  }
}

# 4) Construir probabilidad del ensemble (pesos iniciales 0.7/0.3)
oof_ens <- oof_ens %>%
  mutate(ens_prob = 0.7 * xgb_prob + 0.3 * cart_prob)

# 5) Calcular cutoff que maximiza F1 sobre ens_prob vs obs
pred_obj <- ROCR::prediction(oof_ens$ens_prob, oof_ens$obs)
perf_f1 <- ROCR::performance(pred_obj, "f")
best_idx <- which.max(slot(perf_f1, "y.values")[[1]])
best_cutoff_ens <- slot(perf_f1, "x.values")[[1]][best_idx]
best_f1_ens <- slot(perf_f1, "y.values")[[1]][best_idx]

cat("Cutoff óptimo (ensemble OOF):", round(best_cutoff_ens, 3), "\n")
cat("F1 máximo (OOF ensemble):", round(best_f1_ens, 3), "\n")

# 6) (Opcional) Tuneo rápido del peso del ensemble usando OOF (sin reentrenar)
weights <- seq(0, 1, by = 0.1)
res_w <- sapply(weights, function(w) {
  p <- w * oof_ens$xgb_prob + (1 - w) * oof_ens$cart_prob
  pr <- ROCR::prediction(p, oof_ens$obs)
  pperf <- ROCR::performance(pr, "f")
  max(unlist(slot(pperf, "y.values")))
})
best_w <- weights[which.max(res_w)]
cat("Mejor peso XGB (OOF):", best_w, " -> F1:", round(max(res_w), 3), "\n")
# Podemos usar best_w en lugar de 0.7 si mejora.

# 7) Aplicar en test: generar probabilidades del ensemble y aplicar cutoff_ens
# Asegurar test_ready tiene prob_XGB y prob_CART, si no, calcular
if (!"Prob_Pobre_XGB" %in% names(test_ready)) {
  test_ready$Prob_Pobre_XGB  <- predict(modelo_xgb, newdata = test_ready, type = "prob")[, "Pobre"]
}
if (!"Prob_Pobre_CART" %in% names(test_ready)) {
  test_ready$Prob_Pobre_CART <- predict(modelo_cart, newdata = test_ready, type = "prob")[, "Pobre"]
}

# Usar best_w encontrado
test_ready$Prob_Pobre_Ens <- best_w * test_ready$Prob_Pobre_XGB + (1 - best_w) * test_ready$Prob_Pobre_CART
test_ready$pobre <- ifelse(test_ready$Prob_Pobre_Ens >= best_cutoff_ens, 1, 0)


```

```{r}
cat(" Recalculando cutoff óptimo usando TRAIN completo...\n")

# --- Predicciones del ensemble en el TRAIN ---
pred_xgb_train  <- predict(modelo_xgb, newdata = train_ready, type = "prob")[, "Pobre"]
pred_cart_train <- predict(modelo_cart, newdata = train_ready, type = "prob")[, "Pobre"]

# Ajuste automático del peso del ensemble
pesos <- seq(0.5, 0.9, by = 0.1)
mejor_f1 <- 0
mejor_peso <- 0
mejor_cutoff <- 0

for (w in pesos) {
  prob_ens <- w * pred_xgb_train + (1 - w) * pred_cart_train
  pred_obj <- prediction(prob_ens, train_ready$Pobre)
  perf_f1 <- performance(pred_obj, "f")
  idx <- which.max(slot(perf_f1, "y.values")[[1]])
  f1_max <- slot(perf_f1, "y.values")[[1]][idx]
  cutoff <- slot(perf_f1, "x.values")[[1]][idx]
  if (f1_max > mejor_f1) {
    mejor_f1 <- f1_max
    mejor_cutoff <- cutoff
    mejor_peso <- w
  }
}

cat(" Mejor peso XGB:", round(mejor_peso, 2), "\n")
cat(" Mejor cutoff (train ensemble):", round(mejor_cutoff, 3), "\n")
cat(" F1 máximo estimado:", round(mejor_f1, 3), "\n")

#  Aplicar ensemble al TEST
pred_xgb_test  <- predict(modelo_xgb, newdata = test_ready, type = "prob")[, "Pobre"]
pred_cart_test <- predict(modelo_cart, newdata = test_ready, type = "prob")[, "Pobre"]

test_predic$Prob_Pobre_Ens <- mejor_peso * pred_xgb_test + (1 - mejor_peso) * pred_cart_test
test_predic$pobre <- ifelse(test_predic$Prob_Pobre_Ens >= mejor_cutoff, 1, 0)

# Recuperar ID
if (!"id" %in% names(test_ready)) test_predic$id <- test_hogares_final$id

# --- Guardar CSV Kaggle ---
timestamp <- format(Sys.time(), "%Y%m%d_%H%M")
csv_name <- paste0("XGB_CART_ENSEMBLE_F1opt_", 
                   "w", mejor_peso, "_cut", round(mejor_cutoff,3), "_", timestamp, ".csv")

write.csv(test_predict %>% select(id, pobre), csv_name, row.names = FALSE)


```



```{r}
# Crear el dataframe de submission
submission_xgb <- data.frame(
  id = test_ready$id,
  pobre = test_ready$pobre
)

# Ver distribución de predicciones
table(submission_xgb$pobre)
prop.table(table(submission_xgb$pobre))
```

### 3.1. Seleccion de modelos y entrenamiento

### 3.2. Hiperparametros

### 3.3. Analisis comparativo

### 3.4. Importancia de las caracteristicas

## 4. Conclusiones
















